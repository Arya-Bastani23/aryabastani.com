{"componentChunkName":"component---src-templates-blog-post-js","path":"/projects/prob-segmentation/","result":{"data":{"mdx":{"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"templateKey\": \"project\",\n  \"published\": true,\n  \"title\": \"Recycle Bin Segmentation\",\n  \"slug\": \"prob-segmentation\",\n  \"date\": \"2021-01-31T00:00:00.000Z\",\n  \"featureImage\": \"images/Prob_img.jpg\",\n  \"pinned\": false,\n  \"tags\": [\"ML\", \"Computer Vision\"],\n  \"excerpt\": \"An overview of my solution to solving the problem of visual segmentation of recycle bins.\"\n};\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\nvar PostButton = makeShortcode(\"PostButton\");\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"project-report\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Project Report\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#project-report\",\n    \"aria-label\": \"project report permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"As this was part of my graduate studies I cannot publish the code but the below button will take you to the formal writeup associated with the project. Also the report has \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"much\"), \" more detail than this post will so I highly advice you look through it for more information, here I will be focusing on high level principles and results.\"), mdx(PostButton, {\n    text: \"Report\",\n    target: \"/reports/logit_segmentation.pdf\",\n    mdxType: \"PostButton\"\n  }), mdx(\"h1\", {\n    \"id\": \"introduction\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Introduction\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#introduction\",\n    \"aria-label\": \"introduction permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"In this post we will discuss an approach to detecting US household recycling bins and attempt to understand the shortcomings of the given implementation.\"), mdx(\"h1\", {\n    \"id\": \"problem-statement\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Problem Statement\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#problem-statement\",\n    \"aria-label\": \"problem statement permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"In this problem we are tasked with establishing bounding boxes for recycle bins in images. In particular the formal goal is to first establish a binary segmentation and then use \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.regionprops\",\n    \"target\": \"_self\",\n    \"rel\": \"nofollow\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"regionprops\")), \" from scikit-image to determine a bounding box.\"), mdx(\"h1\", {\n    \"id\": \"approach\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Approach\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#approach\",\n    \"aria-label\": \"approach permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"I opted to train a logistic regression model to classify each pixel in the image as either being a recycle bin or not. For a reference on how to implement logistic regression and what it is refer to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/blog/logistic-regression-intro/\"\n  }, \"this post\"), \" I made before.\"), mdx(\"h1\", {\n    \"id\": \"dataset\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Dataset\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#dataset\",\n    \"aria-label\": \"dataset permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Here I will describe how I accumulated the dataset and any feature engineering done before training.\"), mdx(\"h2\", {\n    \"id\": \"labeling\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Labeling\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#labeling\",\n    \"aria-label\": \"labeling permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"The problem is we were only given images that may or may not contain recycling bins but we do not have labeled data for what regions contain a bin. To solve this, I used the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/jdoepfert/roipoly.py\",\n    \"target\": \"_self\",\n    \"rel\": \"nofollow\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"roipoly\")), \" module to manually section off regions and capture all pixels within the region as recycling bin pixels and labeling all others as not recycling bin.\"), mdx(\"p\", null, mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1168px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/5e4d1779ab6f9c48575a3ae87f3bfbb7/e9cd7/roi_poly.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"70.33333333333334%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADiUlEQVQ4y3WUa0ybVRjHMX4Dh3MbwrgoJCOubGxZdkECTBijwLJuDBgXh4CE6+ZsYjITTfxAhpdEF7/oMEpHKQX69u1bpERX+rZ1FHWoCSQzi4Go+zaSAeUi5VIoP/O+qP3kSZ5z/icnz+/8cy5PxPb2Npubm4RCIba2ttRQ9M489J/+v1DyQ6FtVSstQun++PMR3951893ojzhHZGS3F5fsxuPx4PF6GJFduL1enCNOvF4vHo8XWZaRZTf37o3hcnkYH//5X+A2Dx/+htlsxeFwYrcPIUl2RFFEslmx2yWsosCQYwiraMFqtTA4OKiuiYIFqyBg7jXjdntRWKrDqalpjN1mJGkIi8WCJNmwChZsNgtfD0lIdhG7XUS0CQhCn6olm4DZZMBk7MbQ1cWww7HjMBgMMjExye3OLu4YjPQYjQz092My3qGvvxejqZt+oY8B6wADogWLTcAqDmC1mOjtMfBF5+cYe3r45q4z7NDnG6O0pIzcrCwaaq7QWF/P63V1NLe0cr2lBYPZjlFy0vnZl7Q0NtHS3ExrWxvX3rhORXkZjU2tfGXoCV+K7JI5nZNLzL4YdLoSrupv0PbmDSpr6yhKO0ZyUil7Ndc4+0IuRRnHyXg5k4wTJ8nPyyM9/SgpiUm8pdeHgb5RH/l5Z4mJiaW84lWu6t+mqU1PVU0tRw8c4emE13gq7R2ejzvDxeJCdBdK0RZoKdIWcVBzmOzMHDrab4aBY77vyT9TwLPRu7lUVklNbQOVVTVUKMAUDdHxOiJT64jfe4LC3Fc4r7tEQYEWbUEhKSkHyMzIoqO9YweoPEjlvZ3OymZX1DPqrtXVNZSXV3GxtBxNfAoRzxUTkdDA7qg0tDmZnNeVcK74HIXaIpKSXiTjZGYYqHTDww6SExPQpKZyRHOQxP1xJMTFkn74EMXHT3Elp5rL2fVUH8vh1KGX2B8by749e0hOSiQ6KpJdkZFUXK7YAa6uBpiemuaH0TF+nZjkl/v3Gff58HlkvC4nUw8mWXw0xfz0A36f/AnRbOT2p5/wcUc7t96/yQfvvYu+uZFbH30YdriyEmBtdY2t4CaBlRUW5v0E19dZXw0w8/gxc/PzLCwuMjMzw9KCn83gBmurAeaePGEtsMJfiwss+f3qv1aBGxsbaijnGQgE8Pv9qlaKxtzcnDoqbXl5maWlJTVxbX2d2dnZnYLyT5FQHP4Nb28g2gHUFSQAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"roipoly Example\",\n    \"title\": \"roipoly Example\",\n    \"src\": \"/static/5e4d1779ab6f9c48575a3ae87f3bfbb7/e9cd7/roi_poly.png\",\n    \"srcSet\": [\"/static/5e4d1779ab6f9c48575a3ae87f3bfbb7/eed55/roi_poly.png 300w\", \"/static/5e4d1779ab6f9c48575a3ae87f3bfbb7/7491f/roi_poly.png 600w\", \"/static/5e4d1779ab6f9c48575a3ae87f3bfbb7/e9cd7/roi_poly.png 1168w\"],\n    \"sizes\": \"(max-width: 1168px) 100vw, 1168px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"roipoly Example\"), \"\\n  \")), mdx(\"p\", null, \"After going through the entire set of images (~70 images), I then had a corpus of pixels for each label. To validate this, I created a collage of pixels to see if the captured pixels seemed reasonable. Given the colors I would expect for a recycling bin I think the separation is quite good.\"), mdx(\"p\", null, mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1200px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/4d6a636c7e2841e92fea67810812bd07/26c69/Collage_Bins.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"75%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAB7CAAAewgFu0HU+AAACOklEQVQ4y5WU30/TUBTH92f4ZHQaIOrW/TKCUTKdurUriz/+JRGFjaa3dxuJGF/EEH8jCIIsiAFRQMPCmxF/vIE8jAdBGW2/5t7bjk3Yojc56T2nvaef7zmn9aCybNhotGzH9rlj78Y9zOHGb5j4/HUVswsrWCh+w8z8JzwbncXIxHsMjc3h6cgMXk0XsVj8jncfv/BntrfLNUk9rmOaFg909xVwsO0mwiqFL64hmDQQkAkCioGAQiApBiSZ4NgFDSdTFGvrG/ycZdm1hG7Cnr4CvO29CKlZBJMUwSSBJBsVYy9gcb9soO1qvkFCy4a1s4kbdBxHohoiKcrJ/Ald0PFEhFOypL64jtPXqhL+LXnHIdT6p3HoTA/CHTlIMoXEZMpkVzrbK0QQXslh7Udpf0IWMMubuE5ewtue4Yckp3auxIDCqHVOyfxWlnC91LiG3fkCDp9NI9zBapjldQupOUHIXpLQK/VtbURomiJwK18QklUqiBS3EQaXL2rIiImQXK8plgXY5ha66Di8jFClnJAdZg1hEv0J0XGxN3DqMt1LuKcpt187TckKOt7hbGUOuckEvjhxxqZUn9As/0QnGUNzTEckled0IVUYG5mQagg/SeFL/GNTurKTOBDpxPGLGlpiGprOpdESy/Br83nm96IpmsHRaBonLmlYrSfZHczFpRU8fFHEvUdvMfBkDo9Hl9A/MIXnE8u4O/gGg0PzeDD8AXfuT2F4chlbv37XfssuYfW0/++q/tv8AUx8ncYuUAThAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Recycle Bin Pixels\",\n    \"title\": \"Recycle Bin Pixels\",\n    \"src\": \"/static/4d6a636c7e2841e92fea67810812bd07/8537d/Collage_Bins.png\",\n    \"srcSet\": [\"/static/4d6a636c7e2841e92fea67810812bd07/eed55/Collage_Bins.png 300w\", \"/static/4d6a636c7e2841e92fea67810812bd07/7491f/Collage_Bins.png 600w\", \"/static/4d6a636c7e2841e92fea67810812bd07/8537d/Collage_Bins.png 1200w\", \"/static/4d6a636c7e2841e92fea67810812bd07/26c69/Collage_Bins.png 1280w\"],\n    \"sizes\": \"(max-width: 1200px) 100vw, 1200px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Recycle Bin Pixels\"), \"\\n  \")), mdx(\"p\", null, mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1200px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/cbe2fa5cbe7421bbac21bf9ede184ce4/26c69/Collage_Others.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"75%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAB7CAAAewgFu0HU+AAAB60lEQVQ4y52UX0/bMBTF+wURT7R1mqSxHSfNus80tVH/qJsKQwIeKBplEnsYbyOUZ3hteU5bNTno2iQajHYSliw7N8rJ79wTp4KXkef48Mj/erhCF0UhyzI8Pjzg9vYPkiTBbHaHm5vfmEzOcXExweXlD12je8ldgvv7Gdbr9SvRSnGx2Wx0YTDogbEDKCXAPRdSevB9DuV7ENyB4C44d+F5DqJWgKenxWvBgjDLjGB/0INl1aCUhBBNLSakB0l74UII8wJfNhFFIRaLrYIZVqsV4jgGYzVNSEJ6FYaUptK0XFOGgfxX8K3lr99GYKyKIJClVaIjMqFXovb0bIX+dsI8z7BcLhHHHVisakiIjjchJYf0RSlIdNyzEUVqVw8zXRgO+6izKsJQQRGltm1oCzEj7O4mLAT7/R4aFlkWZd8Km2bvaWoS3hkKTfqmOh1jOVCiDIFoTC9dbV/TchftdvT/UEajoSakBCkM+RIGCRFd0Vvq4adI7SZM0yW63S9wHKZTDnxu0lYSoRJajOhIPFAcn9ut7YIFYRx3sb+/B9e10LBqcBwLjQaDbddh27Svw7EZHLsOzpuYz+fvWy4KdEbpzJ6cnuDs7BTT6RTj8RhXP69wfPy9PNdHh2Nc/7pGmqbvE779a3z0b/MMosCr/apyoToAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Non Bin Pixels\",\n    \"title\": \"Non Bin Pixels\",\n    \"src\": \"/static/cbe2fa5cbe7421bbac21bf9ede184ce4/8537d/Collage_Others.png\",\n    \"srcSet\": [\"/static/cbe2fa5cbe7421bbac21bf9ede184ce4/eed55/Collage_Others.png 300w\", \"/static/cbe2fa5cbe7421bbac21bf9ede184ce4/7491f/Collage_Others.png 600w\", \"/static/cbe2fa5cbe7421bbac21bf9ede184ce4/8537d/Collage_Others.png 1200w\", \"/static/cbe2fa5cbe7421bbac21bf9ede184ce4/26c69/Collage_Others.png 1280w\"],\n    \"sizes\": \"(max-width: 1200px) 100vw, 1200px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Non Bin Pixels\"), \"\\n  \")), mdx(\"h2\", {\n    \"id\": \"feature-engineering\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Feature Engineering\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#feature-engineering\",\n    \"aria-label\": \"feature engineering permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Currently the only features present for each example are the RGB values of each pixel. To attempt to help the model in classifying the pixels I thought it would be beneficial to add the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/HSL_and_HSV\",\n    \"target\": \"_self\",\n    \"rel\": \"nofollow\"\n  }, \"HSV\"), \" color space alongside RGB. In the past, I've used HSV thresholding for simple segmentation so I believe that adding it here will help resolve some as the color is directly encoded in one of the values as opposed to requiring all values in RGB. So for each pixel we'll classify on a feature set that looks like:\"), mdx(\"p\", null, \"$$\\n\", \"[R,G,B,H,S,V]\", \"\\n$$\"), mdx(\"p\", null, \"Given all this information we can continue to model construction and training.\"), mdx(\"h1\", {\n    \"id\": \"model-construction\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Model Construction\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#model-construction\",\n    \"aria-label\": \"model construction permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"As mentioned prior, I chose to implement a logistic regression for the individual binary classification of each pixel.\"), mdx(\"h2\", {\n    \"id\": \"forward-pass\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Forward Pass\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#forward-pass\",\n    \"aria-label\": \"forward pass permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"To construct the model all I needed to do was to create all the necessary functions for the forward pass. Again, I am omitting many of the smaller helper functions and such and giving a general overview of my process here, if you would like a more in depth (tutorial like) post let me know!\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Reshape image for segmenting\\nimg_reshape = np.reshape(img, (-1, 3)) / 255\\nX_img = prep_X(img_reshape)\\n\\n# Classify pixels\\nA, B, _ = img.shape\\nscores = sigmoid(self.w @ X_img.T)\\npred = scores\\nscores_img = np.reshape(pred, (A, B))\\n\\n# Return mask\\nmask_img = np.zeros_like(scores_img)\\nmask_img[scores_img >= self.thresh] = 1\\n\")), mdx(\"h1\", {\n    \"id\": \"training\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Training\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#training\",\n    \"aria-label\": \"training permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"A change I made from my prior blog post was to implement stochastic gradient descent to improve training speed. The training is identical to that of my prior blog post except that the batch used to compute the gradient is a subset of the entire dataset. This is why the training accuracy is quite rough in the below plot.\"), mdx(\"p\", null, mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1200px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/c5f25201cc6e22acc07b19198bc05cd0/26c69/Bin_Training.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"75%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAB7CAAAewgFu0HU+AAABvElEQVQ4y41Ti46bMBC8///ARpGa6BIC5hW/sTEPT7Um0HBJ72pp8crAeHdm5wMAYoz4uqZpwjAMuwhhwDiOKX+3COdjBQshwDmXgvKyLHE+n3E+nZBdr2B5jux6QX7LUvR9jyHQRQHee8zznHASoJQSQohUFQVVsS7bD2ikwakUuNQSv4s7PiuBw2cOVtco6gZcKoyPqhOgtRbGmF35xnnkjIGVJdq2huQNrLrDKo5Oc3TWIvguhXfdRkMCJDCt9cZlIyRKdkPoPTGDn9bCb1gA6aGUglQqHWjrULL8ieiF7H/Fyv8GSOQSh8ZoTDNQVwUQp001QozADuBZ1RfAqqrQNDWs7RCcRejU7uN3I/UtIPHXti2UNohOAvO4sPamov8CTIoaA2MtvOaYxrBrF1u7fy/5lsNFZQ0hFbRogTjvOHsFeK2a5vZFZX5v0Bv+I2/THBGGEd47eN8nx1CH2xziMdiCt3BaYI4x2YgcEx85BeXTPMM7i6Yu8etwwPF4TPYkDXaDvVqPdvIlKb/unPPUQVHk8H2P2/UCqxUKxpLfyRBZlqUCtpa/qra+XHf6iTG2uOLh82dRxqezP+QUlFOOJasKAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Training Curve\",\n    \"title\": \"Training Curve\",\n    \"src\": \"/static/c5f25201cc6e22acc07b19198bc05cd0/8537d/Bin_Training.png\",\n    \"srcSet\": [\"/static/c5f25201cc6e22acc07b19198bc05cd0/eed55/Bin_Training.png 300w\", \"/static/c5f25201cc6e22acc07b19198bc05cd0/7491f/Bin_Training.png 600w\", \"/static/c5f25201cc6e22acc07b19198bc05cd0/8537d/Bin_Training.png 1200w\", \"/static/c5f25201cc6e22acc07b19198bc05cd0/26c69/Bin_Training.png 1280w\"],\n    \"sizes\": \"(max-width: 1200px) 100vw, 1200px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Training Curve\"), \"\\n  \")), mdx(\"p\", null, \"The below code makes up the main portion of all the training code. A change I would make in hindsight is to not make the subset selection entirely stochastic, but instead pre-allocated mini batches.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Prep Training and Test\\nX_train = prep_X(X_train_sub)\\n\\n# Get training dimensions and init weights\\nN_train, D = X_train.shape\\nw = np.random.randn(n_class, D) * 0.0001\\n\\n# Init the gradient and accuracy lists\\ngrad = np.zeros(w.shape)\\nacc_train = []\\nepoch_count = []\\n\\n# Run iterations\\nfor it in range(epochs):\\n\\n    # Stochastic Gradient Descent\\n    # Subset the training data randomly to reduce compute time\\n    N_SGD = int(5e4)\\n    ind_vals = random.sample(range(N_train), N_SGD)\\n    X_SGD = X_train[ind_vals]\\n    y_SGD = y_train[ind_vals]\\n\\n    # Computing the gradient\\n    temp = sigmoid(-y_SGD * (w @ X_SGD.T))\\n    temp = temp * (y_SGD * X_SGD.T)\\n    temp = np.sum(temp, axis=1)\\n    grad = temp / (-N_SGD)\\n\\n    # Print status\\n    if it % 10 == 0:\\n        print(\\\"On iteration: {}\\\".format(it))\\n\\n    # Saving new weights\\n    w = w - lr * (wd * w + grad)\\n\\n    # For my testing, tuning of hyperparameters\\n    if it % 2 == 0:\\n\\n        test = False\\n        if test:\\n            # Save Epoch\\n            epoch_count.append(it+1)\\n\\n            # Training Accuracy\\n            scores = sigmoid(w @ X_SGD.T)\\n            pred_train = np.round(scores)\\n            pred_train[pred_train == 0] = -1\\n            acc_train.append(np.sum(pred_train == y_SGD) / N_SGD)\\n\\n    # Plotting of training and testing accuracy\\n    if test:\\n        import matplotlib.pyplot as plt\\n        plt.plot(epoch_count, acc_train, label=\\\"Training Accuracy\\\")\\n        plt.legend()\\n        plt.show()\\nprint(w)\\nnp.save(\\\"logit_weights.npy\\\", w)\\n\")), mdx(\"h1\", {\n    \"id\": \"evaluation\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Evaluation\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#evaluation\",\n    \"aria-label\": \"evaluation permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Now that we have a trained model, we can go ahead and pass the entire reshaped image through the model to get an array of probabilities that can be reshaped back into an image. From the second image, we can see that the recycling bins are clearly \\\"hotter\\\" than the surrounding pixels. After tuning the threshold to determine the classification we can get to quite a good result as in the third image!\"), mdx(\"p\", null, mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1200px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/86aca30450acefaf39676e03126e51dc/26c69/Bin_0067.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"75%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAB7CAAAewgFu0HU+AAADiklEQVQ4y6WUW0zbZRjGuTTxwhjjEm+WeAHJDsYNDBhaeqAtdLT/FYptR8thm64c3MCRANkEN5DDhhyGymQOXWCwLSPDzIsJW9HAQp0wKqZRyiyUcZApbpiygtrSn4EO5270wi/flzz5Ln7v837PlzeMYHBt/48V/PusccJCd0F+XnjA7Ow8dycnmJkcZ2bSzfTsAp6pOTwTHtzTC7imFxmb8eKa9eKa83Jn3ofnAUwt+ll95CosEAisC5vtC6pKrdQctdJ8LIePaitorDtNQ1UV75Ydo+jIe5R2OCnt8VJ6bYHjfb9RcWOew63XOHGxn5XllQ2gf120t7WQotlBTpaSgn27qC4yU1e8jw/LCynJ3kN9eREf9zio6v6atu+XuXoPztrdmA+9RWRUFA+XlkLA1dXVdXG6pQWZXMRei460lDiaqyz0dRznUo2VLCEW02sC5qx0tKlayhpOUVjbglyr5xVJEmIhg+Xf/wgB/f6Qw9ZPzyG3JJJs0iATR1N52MzZ8gNU5KrZGSXw3GYjm1408GZ2Bufq8inOy0ShVCGRKzBaMnnoW37SYVNTExEx2wiP3Mq2LRHERG1HJ34JVXQEz2yS89SzOp5+XiA3V8Zg+xFmb1+iv/sUeW+kIZXE4fV6nwzFPtBLXWUe9dUFFB5MJ8OkI02vwWzUsT1SzeZwFS+EJxEnU/FO/n5OlBdRX1nEmfqj5O7fw6/3F0PAtf/jXVphzn2L+z9cYO7bC3SeKacg30reISuv5xzAYM5An5aJYMwgMTWTaKWeHbEqtkTGsfXlGGRyJd6NUILBUMvzHgfj9k+YGD7P1HA7justZFv3kmo0ojeY0Oj0JGh2I1cmIJZIkMSrkCrU7IwWIVXswufzPXIYDOIPwD2PA/c355gc7mB6pJMvrzQi6JIR9AZ2p5pISjGgFlKQK5SIxHGIpAqkKi1Rr0pRJGr/ASTI8sqfeMbsjNo+wGFr4XZvM4OfN1JWkoM53YImxYBcrUOaICBTqhGJJYgk8SQIBmLjk0hKNuF7nHIolDvOm3S3lmDrOknf5Rr6r9QyeLWBgc/q6W6r5v2TJbxdfBCLJY1EjZZYiXy9gFgpkCgYHjvceMOZu25cTjujQ18x9p2dcectnCMD/ORx4hodwPvLj3jGhvC4HIwM3aSr6zI91220ne+k90Yffn9go+W12fDv48Yfqklg9T/mTjDIX03scxGuFYBSAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Input Image\",\n    \"title\": \"Input Image\",\n    \"src\": \"/static/86aca30450acefaf39676e03126e51dc/8537d/Bin_0067.png\",\n    \"srcSet\": [\"/static/86aca30450acefaf39676e03126e51dc/eed55/Bin_0067.png 300w\", \"/static/86aca30450acefaf39676e03126e51dc/7491f/Bin_0067.png 600w\", \"/static/86aca30450acefaf39676e03126e51dc/8537d/Bin_0067.png 1200w\", \"/static/86aca30450acefaf39676e03126e51dc/26c69/Bin_0067.png 1280w\"],\n    \"sizes\": \"(max-width: 1200px) 100vw, 1200px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Input Image\"), \"\\n  \"), \"\\n\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1200px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/c0c37a52b4d3e889e2a863031c95c995/42b05/Prob_img.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"75.33333333333333%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEBf/EABYBAQEBAAAAAAAAAAAAAAAAAAMBAv/aAAwDAQACEAMQAAABcmidM6wB3//EABoQAAMBAAMAAAAAAAAAAAAAAAECAwQAExT/2gAIAQEAAQUC02dLd9QM7F5aIPSvlrzOhSX/xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAwEBPwFJ/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAERIf/aAAgBAgEBPwHKS//EABoQAAMBAQEBAAAAAAAAAAAAAAABEQIxIZH/2gAIAQEABj8CmdRFeisuV4cX0mun/8QAGRABAQEAAwAAAAAAAAAAAAAAAREAECFB/9oACAEBAAE/IWjIHWk0Djb1rnhGD3hgYpTv/9oADAMBAAIAAwAAABDg/wD/xAAWEQEBAQAAAAAAAAAAAAAAAAABADH/2gAIAQMBAT8QZyMv/8QAFhEBAQEAAAAAAAAAAAAAAAAAEQEA/9oACAECAQE/EI4wab//xAAbEAEAAwEAAwAAAAAAAAAAAAABABExIXGBof/aAAgBAQABPxAeJagbXiW85aCz5HnuCpWMe5CtJ0gFcPWAMBEG9Z//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Probability Image\",\n    \"title\": \"Probability Image\",\n    \"src\": \"/static/c0c37a52b4d3e889e2a863031c95c995/6c738/Prob_img.jpg\",\n    \"srcSet\": [\"/static/c0c37a52b4d3e889e2a863031c95c995/73b64/Prob_img.jpg 300w\", \"/static/c0c37a52b4d3e889e2a863031c95c995/3ad8d/Prob_img.jpg 600w\", \"/static/c0c37a52b4d3e889e2a863031c95c995/6c738/Prob_img.jpg 1200w\", \"/static/c0c37a52b4d3e889e2a863031c95c995/8b34c/Prob_img.jpg 1800w\", \"/static/c0c37a52b4d3e889e2a863031c95c995/111a0/Prob_img.jpg 2400w\", \"/static/c0c37a52b4d3e889e2a863031c95c995/42b05/Prob_img.jpg 2492w\"],\n    \"sizes\": \"(max-width: 1200px) 100vw, 1200px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Probability Image\"), \"\\n  \"), \"\\n\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1200px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/6697a2ff657f56d957b7937104edc3aa/99e71/Thresh_0067_D4.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"60%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAB7CAAAewgFu0HU+AAABOklEQVQoz2P4++fvfxDYOG3H/2LH+v91/p3/a3zbicIgtSA9G6ZsB5sBMovhz+8/YE534tT/ugz2/20Z/P5bMXijYGsG7/82UIwsDlIL0tMZPxlsBsgsuIGTsmf/t2Tw+u/JHvHfjTkUjl2Zw/47MIT/t4diEB8m58ERAdYzIXMmxEBkF07InPXfnMHjvxtL2H8XxpD/LozB/50ZIHScpM//DGXP/+lKnv9dkcTdWMPAevrTZxBpIIhmCP6/vd30/8Ntmv8PTjX678YQhDCQBWpgGpEGgmgnhuD/O9uM/z/Zqv5/e4vJf0eQYUxoBqaTYKAzQ/D/IA6//1ECPv8jBXzAfGdGMgwEeQvmNUeG0P/2UAyzBCRHtgtBbFfGYGhEEelCXMkGH/ZghyabDCzJBl/CxoWxJmxqZz0AZaQgHrRcADwAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Segmented Image\",\n    \"title\": \"Segmented Image\",\n    \"src\": \"/static/6697a2ff657f56d957b7937104edc3aa/8537d/Thresh_0067_D4.png\",\n    \"srcSet\": [\"/static/6697a2ff657f56d957b7937104edc3aa/eed55/Thresh_0067_D4.png 300w\", \"/static/6697a2ff657f56d957b7937104edc3aa/7491f/Thresh_0067_D4.png 600w\", \"/static/6697a2ff657f56d957b7937104edc3aa/8537d/Thresh_0067_D4.png 1200w\", \"/static/6697a2ff657f56d957b7937104edc3aa/d2cc9/Thresh_0067_D4.png 1800w\", \"/static/6697a2ff657f56d957b7937104edc3aa/99e71/Thresh_0067_D4.png 2000w\"],\n    \"sizes\": \"(max-width: 1200px) 100vw, 1200px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Segmented Image\"), \"\\n  \")), mdx(\"h1\", {\n    \"id\": \"improvements\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Improvements\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#improvements\",\n    \"aria-label\": \"improvements permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"I want to make it clear that this is not a great architecture to solve this problem, but one that is convenient and tractable. As we are treating each pixel as an independent classification problem, there is no spatial correspondence. With modern architectures like CNNs, not only would color play a role in detection but also structure and shape. This is easily shown as a problem where right now all I can do is a rough aspect ratio check but even that can be fooled.\"), mdx(\"p\", null, mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1200px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/c2eba8848ed8d1d3e1647c4375a39ba1/26c69/Bin_0062.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"75%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAB7CAAAewgFu0HU+AAACdklEQVQ4y5WUXUiTYRTHXz+n81UjTUrqKiqwqz5ugqK77rqNCIIuE/Ki7rrrA6VkMuec7cOZZNZCszBI52dsOq3lWi7Xan4Lm5X2uhTNtr2/0DSslh8HDs/hOef8nv/Dc3gE1pgsy2zV/u4RVjdXE+FwBGl6kq9fRpGmxpCmxpmZ/uXS6jq1FE8QDof/gQp/nLSSGPd34XVo8TmN+F0mfC4zHmcVvteV+PrM+FxV+PpqmJsNxQb+VijLLP6QGR/swvdSy8c+A0MuPfZ2De+cJuQxHd9H7rA4omd+6C7zcxsBkfk2u8Dw+w68PaV4HBV4eioYcGgwNVRQ9MhMSX0VqsfVaBpqkUKhja4cXY4nBu3021X0d5fjcWh58ewaB89cRDhWgHDyEsLxfFJPXSbweXq5PhpdR6E0M4d/oI0BhxqXTUO3tZiephvcLL6CYnce4p4DpOTuY8f+QwQmP60Ao7EVyisKR/12eltv0duuxtGi4q1NhcZwHUFIIEEQEAQBMSWZQCAQG7h2bGZCc3jdLbzpvI3bpsbZWYKnS025uZB4hUhSYiJxcfGkp2dsAijLRKIw/MFGc5ORRms9rVYD/ldlGO+rSBOz2ZYqIipEdmXtJBgIrg9c8khExu1sJu+sgYzTT8kvqiHo0VH5oBSlmEVGqhJlcio523M2B5xfCGNrq2XviQKEw1rOq54QcKsxP9SgzMgiLUVBikJBdlb2/4Gr0GgkshzbnleSe+QCwtFyzmkb8bVdRV9dSHySSFJc/PKjZIqZBIObULhkfq+LusZ2Su9Zae7tZ8jTQbejFYulDl2ZDkutBaPehCRJGwz2Fn+cWLU/AYmC9n0x1ZUzAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"False Positive Original\",\n    \"title\": \"False Positive Original\",\n    \"src\": \"/static/c2eba8848ed8d1d3e1647c4375a39ba1/8537d/Bin_0062.png\",\n    \"srcSet\": [\"/static/c2eba8848ed8d1d3e1647c4375a39ba1/eed55/Bin_0062.png 300w\", \"/static/c2eba8848ed8d1d3e1647c4375a39ba1/7491f/Bin_0062.png 600w\", \"/static/c2eba8848ed8d1d3e1647c4375a39ba1/8537d/Bin_0062.png 1200w\", \"/static/c2eba8848ed8d1d3e1647c4375a39ba1/26c69/Bin_0062.png 1280w\"],\n    \"sizes\": \"(max-width: 1200px) 100vw, 1200px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"False Positive Original\"), \"\\n  \"), \"\\n\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1200px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/c462e4b0194a33381101f73c83ccf8d2/99e71/Thresh_0062_D2.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"60%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAB7CAAAewgFu0HU+AAAB6ElEQVQoz52SO2hTYRiGP6KgxdSqoKhDTSbvRdTSaFJtrpqcc5I0OScJkUTxNlhRRCJi25AmbZIeUQfp5OCgiFAq2EEcCnVxE3FsdRFxEBF0c0oeyWURRVJf+P9/ePke3pfvF9qq1+vN09Cj0iw57wTjkSpjWoVboUrzHQtXyEer5HwFHpdm/5hrSH4D1lrGDX+RA+JhUDSOiILXEsIpCgOi4pQwfeIh5y225mr/AraNfHQal2icXJPEb0kQshpo3TqqVSfck8AjCkWj2kHCttGodlQUAqsN3KKjdMVYXuzjy7s9fH6zn4+vbXxdHvkfYAKfxPGIzsMrLhZnDvHCdDA/tZe3c9dWCgw1E/otcQbFILtNJbZpmKA1iXuVwlSqvDKgswlM4LPEGRKd070qykYD7/pTuNZGKJ01O9/yqFrlsKj4pFW5AczaNGI2ndDmFEPrwkxmO1gK1GncM+cLPBvfx8s7Dq4fDOCQJGfsGsZOnbA9xYntGuZIpRNgjUbIB5cKfF/aAT92c89w0y9pztk1tA0Gge407p5hSpkOKtM2zNgoHxa28PNTL6bazy6JktnqIdgV5JhEGBAfeb31sWu1DoDzt5/w/tVFvi1d5nn5JlePm9y/MMHdTJHpdJlJPc+c+fSvCX8B6vLRsG8Xp3wAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"False Positive Detection\",\n    \"title\": \"False Positive Detection\",\n    \"src\": \"/static/c462e4b0194a33381101f73c83ccf8d2/8537d/Thresh_0062_D2.png\",\n    \"srcSet\": [\"/static/c462e4b0194a33381101f73c83ccf8d2/eed55/Thresh_0062_D2.png 300w\", \"/static/c462e4b0194a33381101f73c83ccf8d2/7491f/Thresh_0062_D2.png 600w\", \"/static/c462e4b0194a33381101f73c83ccf8d2/8537d/Thresh_0062_D2.png 1200w\", \"/static/c462e4b0194a33381101f73c83ccf8d2/d2cc9/Thresh_0062_D2.png 1800w\", \"/static/c462e4b0194a33381101f73c83ccf8d2/99e71/Thresh_0062_D2.png 2000w\"],\n    \"sizes\": \"(max-width: 1200px) 100vw, 1200px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"False Positive Detection\"), \"\\n  \")), mdx(\"h1\", {\n    \"id\": \"questions\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Questions\", mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#questions\",\n    \"aria-label\": \"questions permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"As always let me know if you have any questions and I'd be happy to answer!\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Recycle Bin Segmentation","date":"January 31st, 2021","excerpt":"An overview of my solution to solving the problem of visual segmentation of recycle bins.","featureImage":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEBf/EABYBAQEBAAAAAAAAAAAAAAAAAAMBAv/aAAwDAQACEAMQAAABcmidM6wB3//EABoQAAMBAAMAAAAAAAAAAAAAAAECAwQAExT/2gAIAQEAAQUC02dLd9QM7F5aIPSvlrzOhSX/xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAwEBPwFJ/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAERIf/aAAgBAgEBPwHKS//EABoQAAMBAQEBAAAAAAAAAAAAAAABEQIxIZH/2gAIAQEABj8CmdRFeisuV4cX0mun/8QAGRABAQEAAwAAAAAAAAAAAAAAAREAECFB/9oACAEBAAE/IWjIHWk0Djb1rnhGD3hgYpTv/9oADAMBAAIAAwAAABDg/wD/xAAWEQEBAQAAAAAAAAAAAAAAAAABADH/2gAIAQMBAT8QZyMv/8QAFhEBAQEAAAAAAAAAAAAAAAAAEQEA/9oACAECAQE/EI4wab//xAAbEAEAAwEAAwAAAAAAAAAAAAABABExIXGBof/aAAgBAQABPxAeJagbXiW85aCz5HnuCpWMe5CtJ0gFcPWAMBEG9Z//2Q=="},"images":{"fallback":{"src":"/static/c0c37a52b4d3e889e2a863031c95c995/fa2c6/Prob_img.jpg","srcSet":"/static/c0c37a52b4d3e889e2a863031c95c995/90ed1/Prob_img.jpg 200w,\n/static/c0c37a52b4d3e889e2a863031c95c995/a1432/Prob_img.jpg 400w,\n/static/c0c37a52b4d3e889e2a863031c95c995/fa2c6/Prob_img.jpg 800w,\n/static/c0c37a52b4d3e889e2a863031c95c995/1123b/Prob_img.jpg 1600w","sizes":"(min-width: 800px) 800px, 100vw"},"sources":[]},"width":800,"height":602}}}},"fields":{"path":"/projects/prob-segmentation/","readingTime":{"text":"8 min read"}},"tableOfContents":{"items":[{"url":"#project-report","title":"Project Report"},{"url":"#introduction","title":"Introduction"},{"url":"#problem-statement","title":"Problem Statement"},{"url":"#approach","title":"Approach"},{"url":"#dataset","title":"Dataset","items":[{"url":"#labeling","title":"Labeling"},{"url":"#feature-engineering","title":"Feature Engineering"}]},{"url":"#model-construction","title":"Model Construction","items":[{"url":"#forward-pass","title":"Forward Pass"}]},{"url":"#training","title":"Training"},{"url":"#evaluation","title":"Evaluation"},{"url":"#improvements","title":"Improvements"},{"url":"#questions","title":"Questions"}]}},"site":{"siteMetadata":{"title":"Patrick Youssef"}}},"pageContext":{"post_id":"/projects/prob-segmentation/"}},"staticQueryHashes":[]}